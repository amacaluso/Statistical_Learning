##<a name="210_GAM" style="pointer-events: none; cursor: default;" ><font color="black"> 2.1. Generalised Additive Model</font></a>


I GAM sono modelli di tipo additivo che consentono di superare il vincolo di linearità tramite l’introduzione di funzioni più flessibili dei regressori. Nel caso di classificazione binaria la forma assunta dal modello è la seguente: 

$$\log{ \biggl( \frac{P(Y=1| X)}{1-P(Y=1| X) }  \biggr)}=\alpha + \sum_{k=1}^p{f_k( X)}$$

dove ciascuna $f_k$ è una funzione *smooth* non specificata a priori.

In particolare, possiamo pensare di esprimere le varie trasformazioni dei regressori tramite funzioni a tratti definite mediante *basis function*, i.e. $f_k( X_k)=\sum_{m=1}^{M_k}{\beta_{km}h_{km}( X_k)}$.
Date queste premesse, i modelli GAM sono quindi soggetti alla definizione di 3 parametri: 

- il numero di *knots* ovvero, equivalentemente, il numero di segmenti in cui dividere il dominio del regressore $ X_k$

- il posizionamento di tali punti di interruzione

- il tipo di funzioni da adattare in ogni intervallo

A tale proposito, tra le varie opzioni proposte in letteratura abbiamo adottato le *smoothing splines*, i.e. basi di tipo *natural cubic splines* definite su un insieme massimale di nodi identificato da interruzioni posizionate nei valori unici del regressore. Questa soluzione, consente di aggirare il problema della scelta dei 3 parametri e di demandare il controllo sulla complessità del modello ad una regolarizzazione in fase di stima del modello. Infatti, è possibile dimostrare che questo tipo di basi emergono come soluzione al problema di minimizzazione riportato di seguito:

$$f^*=argmin_{f^*}\biggl[ \sum_{i=1}^{n} {(y_i - f(x_i))^2} + \lambda \int{f^{''}(t) dt} \biggr] $$

L'intero problema si traduce quindi nella stima dei coefficienti della funzione $f$ e del parametro di penalizzazione $\lambda$.

Riscrivendo poi il criterio di minimizzazione in forma matriciale sfruttando le forme funzionali scelte per le varie $f_k$, si ottiene:

$$ (\boldsymbol y -\boldsymbol N\theta)^T(\boldsymbol y -\boldsymbol N\theta) +
  \lambda \theta^T \boldsymbol \Omega_N \theta
$$

dove la matrice $\boldsymbol N$ contiene per colonna le basi naturali cubiche relative a ciascun regressore, i.e. $\{N\}_{ik}=N_k(x_i)$, e $\boldsymbol \Omega_N$ è la matrice delle derivate seconde, i.e. $\{\Omega_N\}_{kj}= \int{N_j^{''}(t)N_k^{''}(t) dt}$.

A partire da questa formulazione, è facile notare come la funzione obiettivo riproduca un criterio di minimizzazione che rappresenta una generalizzazione della penalizzazione *ridge*, in quanto lo shrinkage viene controllato da una restrizione $\ell_2$ sulle derivate seconde dello stimatore anzichè sui coefficienti stessi.

Segue che:

$$\hat{\theta}=(\boldsymbol N \boldsymbol N^T + \lambda \boldsymbol \Omega_N)^{-1}\boldsymbol N^T \boldsymbol y$$

e quindi:

$$\begin{equation}
\begin{split}
\boldsymbol{ \hat{f}} &= \boldsymbol N (\boldsymbol N \boldsymbol N^T + \lambda \boldsymbol \Omega_N)^{-1}\boldsymbol N^T \boldsymbol y \\
& = \boldsymbol S_{\lambda} \boldsymbol y
\end{split}
\end{equation}
$$
dove l'operatore lineare $\boldsymbol S_{\lambda}$ che proietta dalle osservazioni alle stime è detto *matrice di smoothing*.

Infine, utilizzando quest'ultima rappresentazione è possibile stabilire un parallelo tra $\boldsymbol S_{\lambda}$ e la matrice di proiezione relativa al metodo dei minimi quadrati, la *hat matrix* $\hat{ \boldsymbol H}$, e definire, per analogia, i *gradi di libertà effettivi (edf)* della smoothing spline come $\text{df}_\lambda=\text{trace}(\boldsymbol S_{\lambda})$.
Questa definizione ci permette una riparametrizzazione più intuitiva della funzione di spline in cui, grazie alla relazione monotona tra $\lambda$ e $\text{df}_\lambda$, possiamo specificare la penalizzazione intrinsecamente attraverso i gradi di libertà effettivi della spline. Ciò risulta praticamente utile nei modelli additivi generalizzati, in quanto ci permette di utilizzare simultaneamente differenti metodi di smoothing pur mantenendo una comparabilità tra di essi in termini di flessibilità.

Passando all'applicazione, in questa analisi sono riportati i risultati ottenuti a partire da entrambe le parametrizzazioni sopra riportate, sviluppando sia un modello ottenuto ottimizzando un parametro relativo ai gradi di libertà comune a tutti i regressori, sia un modello in cui la penalizzazione può variare da covariata a covariata ed è scelta autonomamente dal software.

In particolare, in prima approssimazione abbiamo sfruttato il pacchetto *caret* facendo uso della 10-fold cross validation per selezionare il valore ottimale dei gradi di libertà a partire da una grid-search con edf da 1 a 10. Il valore ottimale selezionato dall'algoritmo è 5, con un'accuratezza di 0.7735 e un AUC di 0.8305. 


```{r, fig.width=9.5, fig.height=4, echo=FALSE}

file = "results/MODELING/CLASSIFICATION/ply_val_gam.Rdata"
load( file )
plot
```



<br></br>
<br></br>

Tuttavia il miglioramento introdotto dalla maggiore complessità è minimo, per questa ragione si potrebbe pensare di scegliere df=4 dal momento che, essendo soggetto a minor variabilità, produrrebbe stime più stabili a scapito di una minima perdita in termini di prestazioni.

Alternativamente, il pacchetto *mgcv* permette di adottare la seconda parametrizzazione e lasciare che sia il software stesso a scegliere un parametro di penalizzazione ottimale (possibilmente diverso per ogni covariata) mediante generalised cross validation.

I risultati riportati di seguito fanno riferimento al GAM composto da smoothing spline per tutti i regressori ad eccezione di *type* (dicotomico).

```{r, fig.width=9.5, fig.height=4, echo=FALSE}

file = "results/MODELING/CLASSIFICATION/rgam.all_summary.Rdata"
load( file )

datatable(df, 
          options = list(pageLength = 13), 
          rownames = F, 
          class = "display")
```

<br></br>
<br></br>

Come previsto a ciascuna variabile è associato un numero di edf diverso. Proprio questa indipendenza nella stima della penalizzazione per ogni regressore permette all'algoritmo di evitare l'aggiunta di complessità non necessaria. Infatti, è interessante notare come per le variabili *density* e *sulphates* il grado stimato è ~1, segno che non è necessario inserire non linearità relativamente a queste covariate. 
D'altra parte, un altro dato rilevante riguarda la significatività di ciascun termine (ultima colonna). In generale i p-value sono molto significativi, ad eccezione di quelli relativi a *fixed.acidity*, *chlorides* e *pH*. Per questa ragione possiamo pensare di escludere queste variabili dal modello ed effettuare un test per verificare che l'adattamento del modello ai dati non peggiori significativamente.
Per fare ciò abbiamo quindi stimato un nuovo modello senza i 3 regressori sopra citati e tenendo bloccati i valori di penalizzazione, così da ottenere modelli annidati ed essere in grado di applicare il test del rapporto delle verosimiglianze:

```{r, fig.width=9.5, fig.height=4, echo=FALSE}

file = "results/MODELING/CLASSIFICATION/test_allVSsig.Rdata"
load( file )

datatable(df, 
          options = list(pageLength = 2), 
          rownames = F, 
          class = "display")
```

<br></br>
<br></br>

Il test riporta un p-value di 0.014, lasciando quindi la conclusione aperta a seconda del livello di significatività $\alpha$ adottato. A scopo illustrativo abbiamo deciso di scegliere $\alpha=0.01$ e concludere che i due modelli non sono statisticamente differenti, per cui è possibile continuare l'analisi con quello più semplice, i.e. senza *fixed.acidity*, *chlorides* e *pH*.

A questo punto, si potrebbe tentare di semplificare ulteriormente il modello limitando l'uso di relazioni non lineari solamente alle variabili che realmente mostrano effetti di questo tipo. Per fare ciò è utile guardare ai grafici delle funzioni spline stimate per ogni regressore riportati di seguito.

```{r fig1, echo=FALSE, out.width = '100%'}
knitr::include_graphics("results/MODELING/CLASSIFICATION/restricted_gam1.png")
```

Esaminando i risultati ottenuti ristimando il modello ridotto senza restrizioni sui parametri di penalizzazione, possiamo notare come per le variabili *volatile.acidity*, *citric.acidity*, *residual.sugar* e *free.sulfur.dioxide* sia difficile dire ad occhio se un effetto non lineare sia davvero necessario. Considerando però le curvature presenti nelle zone in cui le bande di confidenza sono più strette abbiamo deciso di non limitare questi regressori ad un effetto lineare e di lasciare che sia l'algoritmo a scegliere i gradi di libertà ottimali.

```{r fig2, echo=FALSE, out.width = '100%'}
knitr::include_graphics("results/MODELING/CLASSIFICATION/restricted_gam2.png")
```

<br></br>
<br></br>

Per quanto riguarda *total.sulfur.dioxide*, *density*, *sulphates* e *alcohol* abbiamo una situazione abbastaza simile. Ad esclusione di *alcohol*, infatti, per le altre variabili la scelta del tipo di effetto potrebbe essere arbitraria. In questo caso, pur considerando il criterio adottato per le covariate precedenti, abbiamo tuttavia optato per l'utilizzo di un effetto lineare per *density* e *sulphates*, anche in virtù degli edf vicini ad 1 stimati dal software.

Di nuovo, quest'ultimo modello è stato confrontato con quello ristretto mediante la stessa procedura ottenuta prima:

```{r, fig.width=9.5, fig.height=4, echo=FALSE}

file = "results/MODELING/CLASSIFICATION/test_sigVSlin.Rdata"
load( file )

datatable(df, 
          options = list(pageLength = 2), 
          rownames = F, 
          class = "display")
```

<br></br>
<br></br>

Stavolta il p-value risulta pari a 0.068, per cui non c'è abbastanza evidenza sperimentale per rifiutare l'ipotesi nulla che i due modelli si equivalgano in quanto ad adattamento ai dati. In definitiva possiamo scegliere di stimare nuovamente (senza vincoli) il modello senza i regressori *fixed.acidity*, *chlorides* e *pH* e con effetti lineari per le variabili *type*, *density* e *sulphates*. Il modello ha una performance leggermente inferiore rispetto a quello stimato da *caret*, con un'accuratezza di 0.7678 e un AUC di 0.8261. I valori ottimali selezionati dall'algoritmo sono riportati nella seguente tabella:

```{r, fig.width=9.5, fig.height=4, echo=FALSE}

file = "results/MODELING/CLASSIFICATION/rgam.lin_summary.Rdata"
load( file )

datatable(df, 
          options = list(pageLength = 13), 
          rownames = F, 
          class = "display")
```

<br></br>
<br></br>


<br></br>
<br></br>
